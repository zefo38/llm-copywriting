{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"16FteOaylOMO8_NBcYOoL7LCHx8LlzaBS","authorship_tag":"ABX9TyMIu+Si289INxFPUPgxPaHq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"cb6771ba05784050b30506681afce752":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5fb6b40b76e14a4f88362384b3bd34d9","IPY_MODEL_ab4e6e512a874c7bae793e96a9680f72","IPY_MODEL_d81775e5224049c4b3ebe96fdb5124d3"],"layout":"IPY_MODEL_df2a995b737d43c2a9529f5fd5410ab6"}},"5fb6b40b76e14a4f88362384b3bd34d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7341540d44944fe593a0611470f3ad92","placeholder":"​","style":"IPY_MODEL_815475fbafe14632828e27bae6daeb4c","value":"Loading checkpoint shards: 100%"}},"ab4e6e512a874c7bae793e96a9680f72":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d9716941e9d498b9ec1e08ace997b3b","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_69f8acfdc0324cd2b7d8e4571f8acbf7","value":4}},"d81775e5224049c4b3ebe96fdb5124d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b453f913123d46f8a4de100cd7e01e27","placeholder":"​","style":"IPY_MODEL_a3f9b19bb836497084c2065b958b44db","value":" 4/4 [01:14&lt;00:00, 15.86s/it]"}},"df2a995b737d43c2a9529f5fd5410ab6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7341540d44944fe593a0611470f3ad92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"815475fbafe14632828e27bae6daeb4c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8d9716941e9d498b9ec1e08ace997b3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69f8acfdc0324cd2b7d8e4571f8acbf7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b453f913123d46f8a4de100cd7e01e27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3f9b19bb836497084c2065b958b44db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4630555f3bd643b7aad4d83722bddc6e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_756404f2bd354d7da8d2ca16d8719030","IPY_MODEL_09c7ddbe4abc499e92a0d8ed35153739","IPY_MODEL_57075f34541d4696b7eb9944390bf573"],"layout":"IPY_MODEL_b94785cd7b5d491aa34a7dd00f6edcf8"}},"756404f2bd354d7da8d2ca16d8719030":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4d4894677364709a8dad02118edeff8","placeholder":"​","style":"IPY_MODEL_067a4276a93d4d1997941ce63a60eb6c","value":"Loading checkpoint shards: 100%"}},"09c7ddbe4abc499e92a0d8ed35153739":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fe74c8944d3f47749716242f0fba3d01","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_41f0a97f13ae4edd99e1f4a0d8faef2f","value":4}},"57075f34541d4696b7eb9944390bf573":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a996bf4b7544c28a7e0d6579fb3c7db","placeholder":"​","style":"IPY_MODEL_f275a06afc8b439db13be0a781a7a804","value":" 4/4 [00:02&lt;00:00,  1.83it/s]"}},"b94785cd7b5d491aa34a7dd00f6edcf8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4d4894677364709a8dad02118edeff8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"067a4276a93d4d1997941ce63a60eb6c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fe74c8944d3f47749716242f0fba3d01":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41f0a97f13ae4edd99e1f4a0d8faef2f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5a996bf4b7544c28a7e0d6579fb3c7db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f275a06afc8b439db13be0a781a7a804":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# LLaMA-3 Tokenizer  \n","# 1. Import"],"metadata":{"id":"XGhczmgh_PwZ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wfoc5Z3p2MhY"},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForCausalLM"]},{"cell_type":"markdown","source":["model_id = \"allganize/Llama-3-Alpha-Ko-8B-Evo\""],"metadata":{"id":"1izqhABqKpID"}},{"cell_type":"code","source":["model_id = \"allganize/Llama-3-Alpha-Ko-8B-Instruct\"\n","tokenizer = AutoTokenizer.from_pretrained(model_id)"],"metadata":{"id":"6oxR3BYQ-0JP","executionInfo":{"status":"ok","timestamp":1732084023317,"user_tz":-540,"elapsed":978,"user":{"displayName":"혜인","userId":"09109483988618231367"}}},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":["# 2. Encode & Decode"],"metadata":{"id":"-TOaZ5dA_Xeh"}},{"cell_type":"code","source":["llm_input = [\n","    # {\"Card_Name\":\"삼성카드 & MILEAGE PLATINUM(스카이패스)\",\"benefits\":\"3% 캐시백, 영화 할인\"},\n","    {\"Card_Name\":\"KB국민 와이즈카드\", \"benefits\":\"뷰티, 납부, 카페/베이커리, 쇼핑/간편결제, 의료, 교통/주유, 문화, 교육/육아\"}\n","]"],"metadata":{"id":"OyIq-v6O_Mht"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. Template  \n","- user : 사용자 신분 : 사용자가 챗봇에게 질문할 내용이 됩니다.  \n","- system : LLM에게 시키고 싶은 것 : LLM이 어떤 기준을 가지고 작동할지에 대한 설정  \n","- assistant : LLM의 답변  \n"],"metadata":{"id":"dpFmAOyhBGtk"}},{"cell_type":"code","source":["messages = [\n","    {\"role\": \"system\", \"content\":\"당신은 광고 카피라이터입니다. 입력된 정보에 기반하여 기발하고 명확한 카피라이팅 문구를 제작하세요.\"},\n","    {\"role\" :\"user\", \"content\" : llm_input}\n","]"],"metadata":{"id":"8HIIWmFNBDWh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4. ChatTemplate 인코딩 & 디코딩"],"metadata":{"id":"6fC3bXqHB6UK"}},{"cell_type":"code","source":["# ChatTemplate 만들기\n","template_messages = tokenizer.apply_chat_template(\n","    messages,\n","    add_generation_prompt=True,\n","    return_tensors= 'pt' # 파이토치 텐서로 리턴\n","    )\n","print(template_messages)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aR5OVpIoCAFI","executionInfo":{"status":"ok","timestamp":1732084028862,"user_tz":-540,"elapsed":431,"user":{"displayName":"혜인","userId":"09109483988618231367"}},"outputId":"06683219-9518-40a5-ab51-5876878844c7"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[128000, 128006,   9125, 128007,    271,  65895,  83628,  34804, 112601,\n","         103236, 102477, 108157,  34961,  80052,     13,  43449,  53400,  61139,\n","          19954, 126470,  83290,  55216, 102133, 101360, 104167, 111372,  24486,\n","         103236, 102477, 108157, 105876,  54535,  89359,  18918, 114699,  92245,\n","             13, 128009, 128006,    882, 128007,    271,     58,  13922,   5889,\n","          19552,   1232,    364,  30962, 100654, 101607,  75984, 103618, 102668,\n","         101436,  30446,    518,    364,  68244,   1220,   1232,    364, 114448,\n","         102199,     11,  38295,    102,  64189,     11, 103236, 104249,     14,\n","         105010,  13094, 106153,  29102,     11, 121346, 113629,     14,  63375,\n","         104790,  89881,  38187,     11, 101787,  64356,     11, 101999, 102233,\n","             14,  55430, 101314,     11, 115762,     11, 109194,     14, 102946,\n","          54059,   8439,     60, 128009, 128006,  78191, 128007,    271]])\n"]}]},{"cell_type":"markdown","source":["# 5. LLaMA-3 모델 호출하기"],"metadata":{"id":"yEExiD4KDJxm"}},{"cell_type":"code","source":["# 비트 양자화를 위한 패키지입니다. 모델의 용량을 줄여주는 역할을 한다.\n","# 설치 후 세션 다시 시작\n","# !pip install -q -U bitsandbytes"],"metadata":{"id":"7KFDIt2vChP2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n","\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit = True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16\n",")\n","\n","print(model_id)\n","model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["cb6771ba05784050b30506681afce752","5fb6b40b76e14a4f88362384b3bd34d9","ab4e6e512a874c7bae793e96a9680f72","d81775e5224049c4b3ebe96fdb5124d3","df2a995b737d43c2a9529f5fd5410ab6","7341540d44944fe593a0611470f3ad92","815475fbafe14632828e27bae6daeb4c","8d9716941e9d498b9ec1e08ace997b3b","69f8acfdc0324cd2b7d8e4571f8acbf7","b453f913123d46f8a4de100cd7e01e27","a3f9b19bb836497084c2065b958b44db"]},"id":"Wa8tH9GUDXht","executionInfo":{"status":"ok","timestamp":1732084106658,"user_tz":-540,"elapsed":75857,"user":{"displayName":"혜인","userId":"09109483988618231367"}},"outputId":"e1c96d9c-5704-49c2-e661-719e24294e70"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["allganize/Llama-3-Alpha-Ko-8B-Instruct\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb6771ba05784050b30506681afce752"}},"metadata":{}}]},{"cell_type":"code","source":["device = 'cuda'\n","\n","# 모델에 입력할 데이터를 gpu로 옮긴다.\n","model_inputs = template_messages.to(device)\n","model_inputs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wKrI8DKJEJw6","executionInfo":{"status":"ok","timestamp":1732084111997,"user_tz":-540,"elapsed":299,"user":{"displayName":"혜인","userId":"09109483988618231367"}},"outputId":"f64fc0dc-5d32-409e-d26d-ce94c9c79031"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[128000, 128006,   9125, 128007,    271,  65895,  83628,  34804, 112601,\n","         103236, 102477, 108157,  34961,  80052,     13,  43449,  53400,  61139,\n","          19954, 126470,  83290,  55216, 102133, 101360, 104167, 111372,  24486,\n","         103236, 102477, 108157, 105876,  54535,  89359,  18918, 114699,  92245,\n","             13, 128009, 128006,    882, 128007,    271,     58,  13922,   5889,\n","          19552,   1232,    364,  30962, 100654, 101607,  75984, 103618, 102668,\n","         101436,  30446,    518,    364,  68244,   1220,   1232,    364, 114448,\n","         102199,     11,  38295,    102,  64189,     11, 103236, 104249,     14,\n","         105010,  13094, 106153,  29102,     11, 121346, 113629,     14,  63375,\n","         104790,  89881,  38187,     11, 101787,  64356,     11, 101999, 102233,\n","             14,  55430, 101314,     11, 115762,     11, 109194,     14, 102946,\n","          54059,   8439,     60, 128009, 128006,  78191, 128007,    271]],\n","       device='cuda:0')"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["# 답변 종료 토큰 설정\n","terminators = [\n","    tokenizer.eos_token_id,\n","    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n","]"],"metadata":{"id":"TEIMFz_GK4S5","executionInfo":{"status":"ok","timestamp":1732084119105,"user_tz":-540,"elapsed":320,"user":{"displayName":"혜인","userId":"09109483988618231367"}}},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":["### **답변 생성하기** : LLM에서 답변을 받기 위해서는 generate 함수 사용"],"metadata":{"id":"d87EIqBwHJZU"}},{"cell_type":"code","source":["# 모델 입력\n","generated_ids = model.generate(\n","    model_inputs, # 정수 인코딩이 된 프롬프트(chat Template)\n","    max_new_tokens=300, # 모델이 대답할 응답 메시지의 최대 길이\n","    eos_token_id = terminators, # 모델의 텍스트 생성 종료 토큰\n","    repetition_penalty = 1.05 # 반복된 응답 지수. 값이 작아질 수록 반복된 응답을 수행\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-0lNnc3RGWlG","executionInfo":{"status":"ok","timestamp":1732084148635,"user_tz":-540,"elapsed":28229,"user":{"displayName":"혜인","userId":"09109483988618231367"}},"outputId":"224ffb2c-76dd-41a1-b533-16b04803df75"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"]}]},{"cell_type":"code","source":["# batch_decode : 여러 개의 input에 대해 한꺼번에 변환\n","decoded = tokenizer.batch_decode(generated_ids)\n","decoded[0]"],"metadata":{"id":"aPlMZ9RPHxPN","colab":{"base_uri":"https://localhost:8080/","height":271},"executionInfo":{"status":"ok","timestamp":1732084148635,"user_tz":-540,"elapsed":5,"user":{"displayName":"혜인","userId":"09109483988618231367"}},"outputId":"9aecbd13-243e-460f-9ea4-b53745182862"},"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\n당신은 광고 카피라이터입니다. 입력된 정보에 기반하여 기발하고 명확한 카피라이팅 문구를 제작하세요.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n[{\\'Card_Name\\': \\'KB국민 와이즈카드\\', \\'benefits\\': \\'뷰티, 납부, 카페/베이커리, 쇼핑/간편결제, 의료, 교통/주유, 문화, 교육/육아\\'}]<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n**\"The Wiser Choice\"**\\n\\n**\"KB 국민 와이즈카드\"**\\n\\n**\"지금까지의 생활을 더 쉽고 편리하게\"**\\n\\n**\"뷰티와 건강을 위한 다양한 혜택\"**\\n- 매장에서 사용할 수 있는 포인트 적립\\n- 납부와 결제가 간편해진다.\\n\\n**\"일상 생활의 모든 순간을 즐기세요\"**\\n- 카페와 베이커리에서 커피 한 잔과 함께\\n- 쇼핑과 간편결제로 시간을 절약\\n- 의료와 교통, 주유, 문화, 교육, 육아 등 모든 분야에서 편리함을 누리세요.\\n\\n**\"지금 바로 시작하세요\"**\\n- **KB 국민 와이즈카드**로 더 나은 삶을 누리세요!**\\n\\n이 카피는 고객에게 편리함과 혜택을 제공하는 카드의 주요 기능을 강조하면서도, 일상 생활에서의 다양한 경험을 통해 고객이 느끼는 만족감을 표현하고 있습니다. 또한, 카드의 브랜드인 **KB 국민 와이즈카드**의 이미지를 강화하기 위해 \\'지금까지의 생활을 더 쉽고 편리하게\\'라는 문구를 사용했습니다. <|end_of_text|>'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["!pip -q install langchain pypdf chromadb sentence-transformers faiss-gpu langchain-community"],"metadata":{"id":"F68LOFPXOW9k","executionInfo":{"status":"ok","timestamp":1732083980525,"user_tz":-540,"elapsed":3987,"user":{"displayName":"혜인","userId":"09109483988618231367"}}},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":["# 파이프라인 정의  \n","- 랭체인에서 사용할 내용 : 허깅페이스 오픈 LLM을 연결할 파이프라인을 정의  \n","- 허깅페이스의 파이프라인을 생성해서 랭체인의 파이프라인으로 이어주기"],"metadata":{"id":"s6oEdlc2Osr8"}},{"cell_type":"code","source":["from langchain.llms import HuggingFacePipeline\n","from langchain.prompts import PromptTemplate\n","from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n","from transformers import pipeline # 오픈 모델 체이닝\n","from langchain.chains import LLMChain\n","\n","# model_id = \"allganize/Llama-3-Alpha-Ko-8B-Instruct\"\n","# tokenizer = AutoTokenizer.from_pretrained(model_id)\n","\n","# 1. 허깅페이스 파이프라인 정의. LLM은 생성 모델이기 때문에 text-generation 파이프라인을 생성\n","text_generation_pipeline = pipeline(\n","    model = model, # 사용할 모델. 여기서는 LLaMA-3 모델\n","    tokenizer = tokenizer, # LLaMA-3의 토크나이저\n","    task = 'text-generation',\n","    return_full_text=False, # 답변만 생성 결과로 받고 싶은 경우 사용. True로 설정하면 입력 프롬프트까지 모두 나옴\n","    max_new_tokens=300,\n","    temperature=0.7, # 응답의 창의성 조정\n","    top_p=0.9 # 생성 확률의 누적값 기반으로 다양성 제어\n",")\n","\n","\n","#  프롬프트 템플릿 직접 정의\n","prompt_template = \"\"\"\n","<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n","\n","당신은 광고 카피라이터입니다. 주어진 카드 정보와 혜택을 바탕으로 기발하고 명확한 카피라이팅 문구를 제작하는 것이 역할입니다.\n","당신의 문구는 사용자에게 카드의 가치를 한눈에 전달할 수 있어야 하며, 읽는 사람이 혜택을 즉각적으로 이해하고 매력을 느끼게 해야 합니다.\n","당신은 뛰어난 광고 카피라이터입니다. 주어진 카드 정보와 혜택을 바탕으로 창의적이고 감동적인 카피라이팅 문구를 제작하는 것이 역할입니다.\n","- 당신의 문구는 사용자에게 카드의 가치를 한눈에 전달할 수 있어야 하며, 읽는 사람이 혜택을 즉각적으로 이해하고 매력을 느끼게 해야 합니다.\n","- 당신의 문구는 단순한 정보 전달이 아니라, 감정적인 연결을 만들어내야 합니다.\n","- 사용자가 이 카드를 소유했을 때 느낄 수 있는 만족감을 생생하게 그려주세요.\n","- 구체적인 혜택을 중심으로 재미있고 톡톡 튀는 문구를 작성해주세요.\n","\n","<|eot_id|><|start_header_id|>user<|end_header_id|>\n","\n","카드 정보:\n","{llm_input}\n","\n","요청사항:\n","입력된 카드 정보 각각에 대해 3개의 톡톡 튀는 광고 문구를 작성해주세요.\n","각 문구는 다음을 포함해야 합니다:\n","- 카드의 주요 혜택 강조\n","- 감성적 또는 실용적 요소\n","- 이모티콘으로 생동감 추가\n","\n","예시 문구:\n","1. \"커피 한 잔의 행복도 더! ☕ 카페 할인 혜택, 바로 신한카드 SIMPLE로!\"\n","2. \"여행 가방 속 필수템, 대한항공 마일리지 카드✈️로 세계를 담아보세요.\"\n","3. \"월말 지출도 든든하게! 💳 삼성카드 SAVE로 캐시백의 즐거움!\"\n","\n","위와 같은 스타일로 작성해주세요.\n","<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n","\"\"\"\n","\n","# 2. Langchain 파이프라인 정의\n","# 허깅페이스 파이프라인 사용\n","llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n","\n","# 3. Langchain의 프롬프트 템플릿 생성\n","prompt = PromptTemplate(\n","    input_variables=[\"llm_input\"],\n","    template= prompt_template\n",")\n","\n","# llm chain 구축\n","llm_chain = LLMChain(llm=llm, prompt=prompt)\n","\n","llm_input = \"\"\"\n","- 카드 이름: KB국민 와이즈카드\n","- 혜택: 뷰티, 납부, 카페/베이커리, 쇼핑/간편결제, 의료, 교통/주유, 문화, 교육/육아\n","\"\"\"\n","\n","# 실행\n","response = llm_chain.run({\"llm_input\":llm_input})\n"],"metadata":{"id":"M-xVVrVfOf0g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732084233703,"user_tz":-540,"elapsed":32090,"user":{"displayName":"혜인","userId":"09109483988618231367"}},"outputId":"622da320-9af3-4879-c831-cdc06193f6d4"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tf2IrFg-rKrd","executionInfo":{"status":"ok","timestamp":1732084298800,"user_tz":-540,"elapsed":315,"user":{"displayName":"혜인","userId":"09109483988618231367"}},"outputId":"be199ccc-da91-4cb3-e983-e0634854e4de"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["다음은 카드 정보에 맞는 3개의 톡톡 튀는 광고 문구입니다.\n","\n","1. \"뷰티의 기쁨을 더해! 🎀 KB국민 와이즈카드, 뷰티, 납부, 카페/베이커리 혜택으로 여유로운 삶을 즐기세요.\"\n","2. \"지출이 즐거워지는 순간! 🛒 쇼핑/간편결제, 의료, 교통/주유, 문화, 교육/육아 혜택으로 더 많은 즐거움을 누리세요. KB국민 와이즈카드, 당신의 행복을 담아보세요.\"\n","3. \"일상이 더 즐거워지는 순간! 🛬 카드 혜택으로 여유롭게 여행을 즐기세요. KB국민 와이즈카드, 당신의 여행을 더해 보세요.\"\n","\n","이 문구들은 카드의 주요 혜택을 강조하고, 감성적 요소인 여유로운 삶, 더 많은 즐거움, 여유롭게 여행을 즐기기 등이 포함되어 있습니다. 또한, 이모티콘을 사용하여 생동감을 더해 카드의 매력을 전달하고자 했습니다. \n"]}]},{"cell_type":"markdown","source":["# 6. 파인튜닝 : SFTTrainer"],"metadata":{"id":"mSe7lnWXTR67"}},{"cell_type":"code","source":["pip install git+https://github.com/huggingface/trl.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zuUXMslCVSr7","executionInfo":{"status":"ok","timestamp":1732088441899,"user_tz":-540,"elapsed":16003,"user":{"displayName":"혜인","userId":"09109483988618231367"}},"outputId":"4b7499b3-00ba-425a-94b9-4fac554ec00c"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/huggingface/trl.git\n","  Cloning https://github.com/huggingface/trl.git to /tmp/pip-req-build-49ahxfh_\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/trl.git /tmp/pip-req-build-49ahxfh_\n","  Resolved https://github.com/huggingface/trl.git to commit 066fc37bd3381e5de3ac0bb988ce834a050c459f\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: accelerate>=0.34.0 in /usr/local/lib/python3.10/dist-packages (from trl==0.13.0.dev0) (1.1.1)\n","Collecting datasets>=2.21.0 (from trl==0.13.0.dev0)\n","  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl==0.13.0.dev0) (13.9.4)\n","Requirement already satisfied: transformers>=4.46.0 in /usr/local/lib/python3.10/dist-packages (from trl==0.13.0.dev0) (4.46.2)\n","Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl==0.13.0.dev0) (0.26.2)\n","Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl==0.13.0.dev0) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl==0.13.0.dev0) (24.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl==0.13.0.dev0) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl==0.13.0.dev0) (6.0.2)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl==0.13.0.dev0) (0.4.5)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl==0.13.0.dev0) (2.5.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl==0.13.0.dev0) (3.16.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl==0.13.0.dev0) (17.0.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.21.0->trl==0.13.0.dev0)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl==0.13.0.dev0) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl==0.13.0.dev0) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl==0.13.0.dev0) (4.66.6)\n","Collecting xxhash (from datasets>=2.21.0->trl==0.13.0.dev0)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets>=2.21.0->trl==0.13.0.dev0)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.21.0->trl==0.13.0.dev0)\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl==0.13.0.dev0) (3.11.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.0->trl==0.13.0.dev0) (2024.9.11)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.0->trl==0.13.0.dev0) (0.20.3)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl==0.13.0.dev0) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl==0.13.0.dev0) (2.18.0)\n","Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl==0.13.0.dev0) (4.12.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl==0.13.0.dev0) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl==0.13.0.dev0) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl==0.13.0.dev0) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl==0.13.0.dev0) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl==0.13.0.dev0) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl==0.13.0.dev0) (0.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl==0.13.0.dev0) (1.17.1)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl==0.13.0.dev0) (4.0.3)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl==0.13.0.dev0) (0.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.13.0.dev0) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.13.0.dev0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.13.0.dev0) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.13.0.dev0) (2024.8.30)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.34.0->trl==0.13.0.dev0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.34.0->trl==0.13.0.dev0) (3.1.4)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.34.0->trl==0.13.0.dev0) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate>=0.34.0->trl==0.13.0.dev0) (1.3.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.21.0->trl==0.13.0.dev0) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.21.0->trl==0.13.0.dev0) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.21.0->trl==0.13.0.dev0) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.21.0->trl==0.13.0.dev0) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate>=0.34.0->trl==0.13.0.dev0) (3.0.2)\n","Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: trl\n","  Building wheel for trl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for trl: filename=trl-0.13.0.dev0-py3-none-any.whl size=313541 sha256=b47a1983050754ce1a1f448c7ecfd2cf4f030e70c8a418bc9b474b1564b30340\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-k9rgs4v6/wheels/22/0e/42/319b77b2648bb6140ef2b08b0478ede9ca3cc7879fcd022d36\n","Successfully built trl\n","Installing collected packages: xxhash, fsspec, dill, multiprocess, datasets, trl\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 trl-0.13.0.dev0 xxhash-3.5.0\n"]}]},{"cell_type":"code","source":["from trl import SFTTrainer\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","from datasets import load_dataset\n","\n","# 1. 모델 및 토크나이저 로드\n","model_path = \"allganize/Llama-3-Alpha-Ko-8B-Instruct\"\n","model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=\"bfloat16\")\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_path)\n","\n","# 2. 데이터 로드\n","data_file_path = \"/content/diversified_card_with_ad_copies.jsonl\"\n","dataset = load_dataset(\"json\",data_files={\"train\":data_file_path})\n","train_dataset = dataset[\"train\"]\n","\n","print(train_dataset[0])\n","\n","# 3. SFTTrainer 설정\n","trainer = SFTTrainer(\n","    model=model,\n","    train_dataset=train_dataset,\n","    tokenizer=tokenizer,\n","    # max_seq_length=512,\n","    per_device_train_batch_size=2,\n","    gradient_accmulation_steps=8,\n","    num_train_epochs=3,\n","    output_dir=\"./llama-copywrite-finetuned\",\n","    fp16=True, # 혼합 정밀도\n",")\n","\n","# 4. Fine-Tuning 실행\n","trainer.train()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":452,"referenced_widgets":["4630555f3bd643b7aad4d83722bddc6e","756404f2bd354d7da8d2ca16d8719030","09c7ddbe4abc499e92a0d8ed35153739","57075f34541d4696b7eb9944390bf573","b94785cd7b5d491aa34a7dd00f6edcf8","e4d4894677364709a8dad02118edeff8","067a4276a93d4d1997941ce63a60eb6c","fe74c8944d3f47749716242f0fba3d01","41f0a97f13ae4edd99e1f4a0d8faef2f","5a996bf4b7544c28a7e0d6579fb3c7db","f275a06afc8b439db13be0a781a7a804"]},"id":"xti61AQ2TVhS","executionInfo":{"status":"error","timestamp":1732088899319,"user_tz":-540,"elapsed":4858,"user":{"displayName":"혜인","userId":"09109483988618231367"}},"outputId":"346f35c7-336c-4407-939f-7219c1e32806"},"execution_count":55,"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4630555f3bd643b7aad4d83722bddc6e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{'Card Name': '하나 트래블로그 SKYPASS 신용카드', 'Annual_fee': '국내 4만8천원, 해외 4만8천원, 가족겸용 없음', 'Base Record': '조건없음', 'Category_List': \"['항공마일리지']\", 'Ad Copy 1': '\"여행을 꿈꾸신다면? 하나 트래블로그 SKYPASS 신용카드 ✈️로 마일리지 쌓고, 하늘로 떠나요!\"', 'Ad Copy 2': '\"하나 트래블로그 SKYPASS 신용카드로 누리는 특별한 하루, 지금 바로 시작해보세요! 🌟\"', 'Ad Copy 3': '\"하나 트래블로그 SKYPASS 신용카드로 누리는 특별한 하루, 지금 바로 시작해보세요! 🌟\"'}\n"]},{"output_type":"error","ename":"TypeError","evalue":"SFTTrainer.__init__() got an unexpected keyword argument 'per_device_train_batch_size'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-55-662baf384c33>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# 3. SFTTrainer 설정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m trainer = SFTTrainer(\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: SFTTrainer.__init__() got an unexpected keyword argument 'per_device_train_batch_size'"]}]},{"cell_type":"code","source":["# 5."],"metadata":{"id":"1Mwks2Nyg2gH"},"execution_count":null,"outputs":[]}]}